{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings Text Classification with LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Word-Embeddings-Text-Classification-with-LSTMs\" data-toc-modified-id=\"Word-Embeddings-Text-Classification-with-LSTMs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Word Embeddings Text Classification with LSTMs</a></span></li><li><span><a href=\"#Prepping-the-data\" data-toc-modified-id=\"Prepping-the-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Prepping the data</a></span></li><li><span><a href=\"#Implementing-the-model\" data-toc-modified-id=\"Implementing-the-model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Implementing the model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Inference\" data-toc-modified-id=\"Inference-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Inference</a></span></li></ul></li><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Resources</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Resources-to-understand-the-embedding-layer\" data-toc-modified-id=\"Resources-to-understand-the-embedding-layer-4.0.0.1\"><span class=\"toc-item-num\">4.0.0.1&nbsp;&nbsp;</span>Resources to understand the embedding layer</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_W0fHuId9xsG"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer,text_to_word_sequence\n",
    "import tensorflow as tf\n",
    "from utils import f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "g-qmeBswAswD",
    "outputId": "d3bd5069-c365-4668-94ef-00fcdb63eaf3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\",usecols=[\"text\",\"target\"]);df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "iZ50ouzXEz6m",
    "outputId": "0ae0d7ba-3d4d-4046-d34c-14a663888ad2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9dRK0GXUBG-o"
   },
   "outputs": [],
   "source": [
    "# We need a token for words that are not in the vocabulary for the model to distinguish.\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "# Now we need to create a tokenizer to convert sentences into sequences of integers.\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(df.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-v3dQzS_BJmN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size is 22701\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index)\n",
    "print(\"Vocabulary size is\",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f815c38cd90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets plot a historgram to decide on the maximum sequence length\n",
    "\n",
    "df.text.apply(len).hist()\n",
    "# Y axis is the frequency\n",
    "# X axis is the sentence length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IVN4WHfiBPP8"
   },
   "outputs": [],
   "source": [
    "max_length = 150 # Most sequences are smaller than 150.\n",
    "sequences = tokenizer.texts_to_sequences(df.text) # Now the sentences are converted to integers\n",
    "\n",
    "# In order to make all batches the same length we need the senteces to be the same length.\n",
    "# To accomplish this we pad sentences (inputs) from the right.\n",
    "padding_type='post'\n",
    "# Some of the sentences are longer than the sequence length we specified, \n",
    "# so we have to truncate the sequences.\n",
    "trunc_type = 'post'\n",
    "\n",
    "padded = pad_sequences(sequences,maxlen=max_length,padding=padding_type,truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence before padding [190, 46, 230, 800, 6955, 6956, 1405]\n",
      "Sequence after padding [ 190   46  230  800 6955 6956 1405    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(\"Sequence before padding\",sequences[idx])\n",
    "print(\"Sequence after padding\",padded[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Qs22VXNkBQ7U",
    "outputId": "773860ba-89e5-48a3-8349-d5986f512e66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5709, 150), (1904, 150))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can not split the data into train and test.\n",
    "# The models will take sequences of integers are input and output 1 or 0.\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(padded,df.target, random_state = 0)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "FQmx88NYBWec",
    "outputId": "a4965f15-e927-4c70-b5d8-6f41ffd41cee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 300, 100)          2270200   \n",
      "_________________________________________________________________\n",
      "bidirectional_13 (Bidirectio (None, 64)                34048     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,312,697\n",
      "Trainable params: 2,312,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100 # This is a hyperparameter we can play with\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['acc',f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "U_TqOtyvBcCJ",
    "outputId": "fc928249-538c-4f09-d1a1-844651862183"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "179/179 [==============================] - 9s 50ms/step - loss: 0.5423 - acc: 0.7234 - f1: 0.5361 - val_loss: 0.4400 - val_acc: 0.8036 - val_f1: 0.7156\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 8s 44ms/step - loss: 0.2758 - acc: 0.8891 - f1: 0.8600 - val_loss: 0.4737 - val_acc: 0.7962 - val_f1: 0.7485\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 8s 44ms/step - loss: 0.1221 - acc: 0.9587 - f1: 0.9497 - val_loss: 0.6082 - val_acc: 0.7810 - val_f1: 0.7356\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "print(\"Training Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "bGlIzgQeBed6",
    "outputId": "cf835a35-e787-4e3e-8e27-57e1eb1221ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-63-1aee392766bc>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1107\n",
      "           1       0.76      0.71      0.74       797\n",
      "\n",
      "    accuracy                           0.79      1904\n",
      "   macro avg       0.78      0.78      0.78      1904\n",
      "weighted avg       0.79      0.79      0.79      1904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "preds = model.predict_classes(X_test)\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iax8-23pGwaD"
   },
   "source": [
    "# Resources\n",
    "\n",
    "#### Resources to understand the embedding layer\n",
    "\n",
    "https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work\n",
    "https://www.kaggle.com/rajmehra03/a-detailed-explanation-of-keras-embedding-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Real or Not LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
